// test-ai-setup.js - Test script to verify AI setup
const fetch = require('node-fetch');

async function testBackend() {
    console.log('ğŸ§ª Testing AI Backend Setup...\n');
    
    try {
        // Test 1: Health Check
        console.log('1. Testing backend health...');
        const healthResponse = await fetch('http://localhost:3001/api/health');
        
        if (healthResponse.ok) {
            const health = await healthResponse.json();
            console.log(`   âœ… Backend is running`);
            console.log(`   ğŸ“Š Provider: ${health.provider}`);
            console.log(`   ğŸ•’ Status: ${health.status}`);
        } else {
            console.log(`   âŒ Backend health check failed: ${healthResponse.status}`);
            return;
        }
        
        // Test 2: AI Chat Endpoint
        console.log('\n2. Testing AI chat endpoint...');
        const chatResponse = await fetch('http://localhost:3001/api/ai/chat', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                message: 'Hello, can you help with product recommendations?',
                context: {
                    inventory: [
                        { id: 'TEST-001', name: 'Test Product', stock: 10, price: 100 }
                    ],
                    customers: [],
                    quoteItems: []
                }
            })
        });
        
        if (chatResponse.ok) {
            const chatData = await chatResponse.json();
            console.log(`   âœ… AI chat working`);
            console.log(`   ğŸ“ Response: ${chatData.response.substring(0, 100)}...`);
            console.log(`   ğŸ¤– Provider: ${chatData.provider}`);
        } else {
            console.log(`   âŒ AI chat failed: ${chatResponse.status}`);
            const error = await chatResponse.text();
            console.log(`   ğŸ“„ Error: ${error}`);
        }
        
        console.log('\nğŸ‰ All tests passed! Your AI system is ready.');
        
    } catch (error) {
        console.log(`âŒ Test failed: ${error.message}`);
        console.log('\nğŸ”§ Troubleshooting:');
        console.log('1. Make sure backend is running: cd backend && npm start');
        console.log('2. Check if Ollama is running: ollama serve');
        console.log('3. Verify .env configuration in backend folder');
    }
}

async function testOllama() {
    console.log('\nğŸ¤– Testing Ollama connection...');
    
    try {
        const response = await fetch('http://localhost:11434/api/tags');
        if (response.ok) {
            const data = await response.json();
            console.log('   âœ… Ollama is running');
            console.log(`   ğŸ“¦ Available models: ${data.models?.map(m => m.name).join(', ')}`);
        } else {
            console.log('   âŒ Ollama not responding');
            console.log('   ğŸ’¡ Run: ollama serve');
        }
    } catch (error) {
        console.log('   âŒ Ollama not available');
        console.log('   ğŸ’¡ Install Ollama from: https://ollama.ai');
    }
}

// Run tests
async function runTests() {
    await testBackend();
    await testOllama();
    
    console.log('\nğŸ“‹ Quick Commands:');
    console.log('Start backend: cd backend && npm start');
    console.log('Start frontend: npm start');
    console.log('Test Ollama: ollama run deepseek-r1:8b "Hello"');
    console.log('Health check: curl http://localhost:3001/api/health');
}

runTests().catch(console.error);
